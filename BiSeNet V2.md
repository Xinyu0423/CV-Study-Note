# BiSeNet V2
1. https://zhuanlan.zhihu.com/p/141692672?utm_id=0

## 和BiSeNet的相同点和区别
1. 和BiSeNet相同，都是通过双边分割网络，即Spatial Path（细节分支）和Context Path（语义分支）来实现高精度和高效率的实时语义分割。
   1. 其中细节分支记录了较多图片原本的信息，具有宽通道和浅层，用于捕获低层细节并生成高分辨率的特征表示
   2. 语义分支则保留了图片的抽象能力，最后卷积形成的 feature map拥有较大感受野，通道窄，层次深，获取高层次语义语境。
2. 与BiSeNet不同的是，BiSeNet使用FFM作为Spatial Path和Context Path的聚合策略，而在BiseNet V2中，使用了一个引导聚合层(Aggreation Layer)来增强相互连接和融合这两种类型的特征表示。此外，还设计了一种增强型训练策略(Booster)，在不增加任何推理代价的情况下提高分割性能。
   [![2023-03-21-20-02-36.png](https://i.postimg.cc/nLvm3Z6F/2023-03-21-20-02-36.png)](https://postimg.cc/3yxWRM8V)

## 细节分支
1. 和BiSeNet相同，细节分支负责空间细节（即保留了很多图像原本的信息），该分支需要丰富的信道容量（很多的channel）来编码丰富的空间细节信息。同时，因为细节分支只关注底层细节，所以我们可以为这个分支设计一个小跨度的浅层结构（即卷积的次数较少）。总体而言，细节分支的关键概念是使用宽通道和浅层来处理空间细节

## 语义分支
1. 与细节分支并行，语义分支旨在捕获高级语义（即有很强的抽象能力）。该分支的信道容量（channel数）较低，而空间细节可以由细节分支提供。
2. 语义分支采用快速下采样策略提高了特征表示的层次，快速扩大了接受域。高级语义需要大量的接受域。因此，语义分支使用全局平均池嵌入全局上下文响应。

## 聚合层
1. 细节分支和语义分支的特征表示是互补的，其中一个不知道另一个的信息。因此，设计了一个聚合层来合并这两种类型的特性表示。由于采用了快速下采样策略，语义分支的输出空间维度比细节分支小，所以需要对语义的输出特征图进行向上采样分支以匹配细节分支的输出。
2. 由于细节分支是低级的，而语义分支是高级的。因此，简单的组合忽略了这两类信息的多样性，导致性能下降和难以优化。
3. 为了解决这个问题，我们提出双边引导的聚合层融合来自两个分支的互补信息，如图所示。该层使用的是上下文信息语义分支用来指导细节分支的特征响应。通过不同的尺度指导，可以捕获不同的尺度特征表示，这些特征表示对多尺度信息进行了固有的编码。同时，与简单的组合方式相比，这种引导方式可以使两个分支之间进行有效的通信。
   [![2023-03-31-10-00-38.png](https://i.postimg.cc/Nj9Hnsr6/2023-03-31-10-00-38.png)](https://postimg.cc/k2CG6dsG)

## FCN
1. 对于一般的分类CNN网络，如VGG和Resnet，都会在网络的最后加入一些全连接层，经过softmax后就可以获得类别概率信息。但是这个概率信息是1维的，即只能标识整个图片的类别，不能标识每个像素点的类别，所以这种全连接方法不适用于图像分割。
2. 而FCN提出可以把后面几个全连接都换成卷积，这样就可以获得一张2维的feature map，后接softmax获得每个像素点的分类信息，从而解决了分割问题，如图
   [![2023-03-31-09-32-26.png](https://i.postimg.cc/pd5YHXNY/2023-03-31-09-32-26.png)](https://postimg.cc/VS1b9wkd)
3. 从图上可以看出在卷积完成后，分类的CNN网络将原本的feature map摊平后通过FC层产出了分类信息。而FCN在卷积完成后，并没有将原本卷积进行摊平操作，而是将FC换成了卷积，从而得到一个二维的feature map已完成分割问题

## 上采样（upsampling）
1. 上采样一般包括两种方式
   1. Resize，如双线性插值直接缩放，类似于图像缩放（这种方法在原文中提到）
   2. Deconvolution，也叫Transposed Convolution
2. 对于一般卷积，输入蓝色4x4矩阵，卷积核大小3x3。当设置卷积参数pad=0，stride=1时，卷积输出绿色2x2矩阵，如图
   [![2023-03-31-09-40-10.png](https://i.postimg.cc/3rPxW8Db/2023-03-31-09-40-10.png)](https://postimg.cc/237DKfG4)
3. 而对于反卷积，相当于把普通卷积反过来，输入蓝色2x2矩阵（周围填0变成6x6），卷积核大小还是3x3。当设置反卷积参数pad=0，stride=1时输出绿色4x4矩阵
   [![2023-03-31-09-42-09.png](https://i.postimg.cc/BnFDt762/2023-03-31-09-42-09.png)](https://postimg.cc/Js1t2qjh)
4. 传统的网络是subsampling的，对应的输出尺寸会降低；upsampling的意义在于将小尺寸的高维度feature map恢复回去，以获得的每格像素点的分类信息为mask，以便做pixelwise prediction，获得每个点的分类信息。

## 深度可分离卷积（Depthwise Separable Convolution）
1. Depthwise Convolution的计算非常简单，它对输入feature map的每个通道分别使用一个卷积核，然后将所有卷积核的输出再进行拼接得到它的最终输出，如图中的Depthwise Convolution部分所示。
   [![2023-03-31-09-50-14.png](https://i.postimg.cc/XvSV7QGG/2023-03-31-09-50-14.png)](https://postimg.cc/Mn5k90Yq)
2. DSC作为普通卷积的一种替代品，它的最大优点是计算效率非常高。因此使用DSC构建轻量级模型是当下非常常见的做法。不过DSC的这种高效性是以低精度作为代价的。
   
## 全局平均池化（GAP，Global Average Pooling）
[![2023-03-31-09-16-01.png](https://i.postimg.cc/BbcmfwG5/2023-03-31-09-16-01.png)](https://postimg.cc/BPbTxpbt)
1. 通常来说，用图像分类问题举例，在不使用GAP时，完成卷积后会将卷积网络提取出来的特征（feature map）输入到softmax全连接层对应不同的类别，如图左边Fully Connected Layer，之后将feature map摊平成一堆向量，每格向量对应一种分类类别的概率
2. Gap是将每个通道的二维图像做平均，省去了FC层的过程，也就是每格通道对应一个均值，如图右
3. GAP的优势：
   1. 抑制过拟合
      1. 传统卷积使用直接拉平做全连接层的方式，依然保留了大量的空间信息，而GAP不同，将空间上的信息直接用均值代替，相比之下GAP网络参数会更少，而全连接更容易在大量保留下来的空间信息上面过拟合。
   2. 可解释的雏形。
      1. 因为GAP是直接在feature map上进行平均处理，而没有经过FC层摊平操作，因此具有更好的解释性，GAP相比全连接更加自然地加强了类别和feature map之间的联系。
   3. 输入尺寸更加灵活。
4. 缺点：
   1. 训练时收敛的速度会变慢





